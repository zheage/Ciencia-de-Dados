{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f83cd1c7-b891-4ca5-8735-9c9adf376c9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Uso de SQL diretamente com spark.sql()\n",
    "\n",
    "- `spark.sql()` √© uma fun√ß√£o da API do PySpark que permite executar comandos SQL diretamente no engine distribu√≠do do Spark.\n",
    "\n",
    "| Fonte                                | Como acessar                            |\n",
    "| ------------------------------------ | --------------------------------------- |\n",
    "| **Tabelas Delta**                    | `\"SELECT * FROM bronze.clientes\"`       |\n",
    "| **Views tempor√°rias**                | Criadas com `createOrReplaceTempView()` |\n",
    "| **Tabelas externas (Unity Catalog)** | `catalog.schema.tabela`                 |\n",
    "| **Arquivos CSV/Parquet**             | Registrando como tabela ou view         |\n",
    "\n",
    "Criando views para uso com SQL:\n",
    "\n",
    "```python\n",
    "df = spark.read.parquet(\"/mnt/silver/clientes\")\n",
    "df.createOrReplaceTempView(\"clientes_silver\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b28774a-a06d-446e-913e-b5bd2864548b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  clientes \n",
    "WHERE \n",
    "  score > 700\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6e5aba2-d47c-418b-974a-dd143adfe24b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Registro de views tempor√°rias e permanentes\n",
    "\n",
    "## üü¢ 1. View Tempor√°ria\n",
    "\n",
    "\n",
    "Uma view tempor√°ria existe apenas na sess√£o atual do Spark. Ela √© √∫til quando voc√™ quer acessar um DataFrame via spark.sql() sem salv√°-lo em disco. Para cri√°lo basta usar `df.createOrReplaceTempView()`\n",
    "\n",
    "- N√£o persiste em disco.\n",
    "- S√≥ existe enquanto a SparkSession estiver ativa.\n",
    "- Pode ser substitu√≠da com createOrReplaceTempView.\n",
    "\n",
    "## üü° 2. View Global Tempor√°ria\n",
    "\n",
    "Uma global temp view √© vis√≠vel em todas as sess√µes do Spark enquanto o aplicativo estiver ativo e pode ser criada com `df.createOrReplaceGlobalTempView()`\n",
    "\n",
    "- Namespace fixo: global_temp.\n",
    "- √ötil quando se compartilha dados entre diferentes notebooks no mesmo app.\n",
    "- Tamb√©m n√£o persiste ap√≥s o encerramento da aplica√ß√£o.\n",
    "\n",
    "## üî¥ 3. View Permanente (Tabela)\n",
    "\n",
    "Se quiser persistir os dados em disco (e acessar depois da sess√£o encerrar), voc√™ deve salvar como tabela, utilizando `df.write.saveAsTable()`\n",
    "\n",
    "- Armazenada em disco (geralmente em formato Delta ou Parquet).\n",
    "- Persiste entre sess√µes.\n",
    "- Registrada no metastore (geralmente Hive ou Unity Catalog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9eda334-ed84-41c5-bef9-3341607431ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "df_iris = spark.createDataFrame(iris_df)\n",
    "display(df_iris.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13afad7e-08dc-4975-8cd6-96bcab210cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_iris.createOrReplaceTempView(\"global_temp_iris\")\n",
    "# df_iris.createOrReplaceGlobalTempView(\"global_temp_iris\") <- view global, pode ser acessada usando global_temp \n",
    "\n",
    "query_iris = \"\"\"\n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  global_temp_iris \n",
    "WHERE \n",
    "  target = 1\n",
    "\"\"\"\n",
    "\n",
    "display(spark.sql(query_iris).limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04 - PySpark SQL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
